{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification thourgh deep learning \n",
    "\n",
    "(Classic feed forward with SGD for now, won't have the time to experiment on\n",
    "\n",
    "RNN and LSTM to benefit from temporality of data. Going further section)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "plt.style.use('seaborn-poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load prepared data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data_formatter\n",
    "\n",
    "data_set = pd.read_csv(\"prepared_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider features only from the past event for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_events_as_features = 1\n",
    "\n",
    "X, y = data_formatter.prepare_data_set(data_set, nb_events_as_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, validation, test split for simple algorithms comparison\n",
    "\n",
    "Note that we can't use cross validation given the temporality of the data.\n",
    "\n",
    "Cross validation would introduce *future bias* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proportion_train = 0.8\n",
    "proportion_validation = 0.1\n",
    "\n",
    "cut_train = round(X.shape[0] * proportion_train)\n",
    "cut_validation = round(X.shape[0] * (proportion_train + proportion_validation))\n",
    "\n",
    "X_train, y_train = X.iloc[:cut_train,:], y.iloc[:cut_train]\n",
    "X_validation, y_validation = X.iloc[cut_train:cut_validation,:], y.iloc[cut_train:cut_validation]\n",
    "X_test, y_test = X.iloc[cut_validation:,:], y.iloc[cut_validation:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_validation = scaler.transform(X_validation)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "train_null_accuracy = y_train.value_counts()[0] / len(y_train)\n",
    "test_null_accuracy = y_test.value_counts()[0] / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert up/down to one hot encoded output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "Name: binaryOutput, dtype: int64\n",
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:3])\n",
    "y_train = to_categorical(y_train)\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Keras components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define and train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy  : 0.5040145157632117\n",
      "Epoch 1/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6859 - acc: 0.5655     \n",
      "Epoch 2/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6732 - acc: 0.5837     \n",
      "Epoch 3/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6707 - acc: 0.5873     \n",
      "Epoch 4/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6688 - acc: 0.5920     \n",
      "Epoch 5/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6673 - acc: 0.5932     \n",
      "Epoch 6/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6667 - acc: 0.5942     \n",
      "Epoch 7/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6660 - acc: 0.5965     \n",
      "Epoch 8/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6646 - acc: 0.5980     \n",
      "Epoch 9/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6649 - acc: 0.5970     \n",
      "Epoch 10/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6642 - acc: 0.5996     \n",
      "Epoch 11/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6627 - acc: 0.6029     \n",
      "Epoch 12/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6626 - acc: 0.6033     \n",
      "Epoch 13/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6626 - acc: 0.6023     \n",
      "Epoch 14/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6613 - acc: 0.6034     \n",
      "Epoch 15/15\n",
      "22045/22045 [==============================] - 0s - loss: 0.6615 - acc: 0.6042     \n"
     ]
    }
   ],
   "source": [
    "# Layer dimensions\n",
    "\n",
    "N = X_train.shape[1]\n",
    "H = 40\n",
    "K = 2\n",
    "\n",
    "# Stack layers and compile NN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(H, input_dim=N))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dense(K))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=optimizers.SGD(lr=0.1),\n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('{:15}: {:>12}'.format('Null accuracy', train_null_accuracy))\n",
    "\n",
    "# Train NN\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=15, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.56552506233997479,\n",
       "  0.58366976634908296,\n",
       "  0.58725334542709895,\n",
       "  0.59201633022144606,\n",
       "  0.59324109775729661,\n",
       "  0.59423905646727992,\n",
       "  0.59650714447450193,\n",
       "  0.59800408258003346,\n",
       "  0.59700612380515961,\n",
       "  0.59963710588726438,\n",
       "  0.60285779088499003,\n",
       "  0.60326604671990902,\n",
       "  0.60226808801803711,\n",
       "  0.60344749378033247,\n",
       "  0.60421864367526357],\n",
       " 'loss': [0.68586595794678162,\n",
       "  0.67323588640896959,\n",
       "  0.67071030536296006,\n",
       "  0.66883709198710972,\n",
       "  0.66730123401418184,\n",
       "  0.66668719395836296,\n",
       "  0.66595028315739013,\n",
       "  0.66459086720812044,\n",
       "  0.66489869684122893,\n",
       "  0.66422362694207115,\n",
       "  0.6626843394187335,\n",
       "  0.66261714465441302,\n",
       "  0.66256572368004929,\n",
       "  0.66128203154259135,\n",
       "  0.66150275946041981]}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the NN on out of sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688/2756 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(X_test, y_test, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.75167188173800659, 0.52140783744557329]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
